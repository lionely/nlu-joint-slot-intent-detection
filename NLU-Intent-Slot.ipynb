{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "This notebook contains code for the purpose of implementing a joint-intent-slot-filling RNNN described in (put paper here).\n",
    "Code is based off of: https://github.com/DSKSD/RNN-for-Joint-NLU\n",
    " and https://github.com/D2KLab/botcycle/blob/master/brain/botcycle/nlu/joint/data.py\n",
    " \n",
    "**test tube**: https://github.com/williamFalcon/test-tube\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "USE_CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 50\n",
    "SEED = 423\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Data in\n",
    "We are using theAir Travel Information System (ATIS) dataset(I believe it is originally from UPenn, need to verify)\n",
    "It uses the Inside-Out-Beginning tag format(IOB) described here : https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)\n",
    "\n",
    "The typical structure is:\n",
    "\n",
    "Sentence (tokens), Slots to match each token, Intent.\n",
    "\n",
    "Found a preprocessed atis file from, thanks to: https://github.com/D2KLab/botcycle/tree/master/nlu/data/atis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/preprocessed/fold_train.json', 'r') as f:\n",
    "    atis_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'words': ['i',\n",
       "  'want',\n",
       "  'to',\n",
       "  'fly',\n",
       "  'from',\n",
       "  'baltimore',\n",
       "  'to',\n",
       "  'dallas',\n",
       "  'round',\n",
       "  'trip'],\n",
       " 'slots': ['O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-fromloc.city_name',\n",
       "  'O',\n",
       "  'B-toloc.city_name',\n",
       "  'B-round_trip',\n",
       "  'I-round_trip'],\n",
       " 'length': 10,\n",
       " 'intent': 'atis_flight'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atis_json['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(list_of_lists):\n",
    "    \"\"\"Flattens from two-dimensional list to one-dimensional list\"\"\"\n",
    "    return [item for sublist in list_of_lists for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_sequences(data, length=MAX_LENGTH):\n",
    "    \"\"\"\n",
    "    Fixes the input and output sequences length, adding padding or truncating if necessary\n",
    "    :param data json file containing entries from atis dataset.\n",
    "    :param length the fixed length of the sentence.\n",
    "    \"\"\"\n",
    "    for sample in data['data']:\n",
    "        # adjust the sequence of input words\n",
    "        if len(sample['words']) < length:\n",
    "            # add <EOS> and <PAD> if sentence is shorter than maximum length\n",
    "            sample['words'].append('<EOS>')\n",
    "            while len(sample['words']) < length:\n",
    "                sample['words'].append('<PAD>')\n",
    "        else:\n",
    "            # otherwise truncate and add <EOS> at last position\n",
    "            sample['words'] = sample['words'][:length]\n",
    "            sample['words'][-1] = '<EOS>'\n",
    "\n",
    "        # adjust in the same way the sequence of output slots\n",
    "        if len(sample['slots']) < length:\n",
    "            sample['slots'].append('<EOS>')\n",
    "            while len(sample['slots']) < length:\n",
    "                sample['slots'].append('<PAD>')\n",
    "        else:\n",
    "            sample['slots'] = sample['slots'][:length]\n",
    "            sample['slots'][-1] = '<EOS>'\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabularies(train_data):\n",
    "    \"\"\"\n",
    "    Collect the input vocabulary, the slot vocabulary and the intent vocabulary\n",
    "    :param train_data the training data containing words,slots and intent.\n",
    "    \"\"\"\n",
    "    # from a list of training examples, get three lists (columns)\n",
    "    data = train_data['data']\n",
    "    seq_in = [sample['words'] for sample in data]\n",
    "    vocab = flatten(seq_in)\n",
    "    # removing duplicated but keeping the order\n",
    "    v = ['<PAD>', '<SOS>', '<EOS>'] + vocab\n",
    "    vocab = sorted(set(v), key=lambda x: v.index(x)) # https://docs.python.org/3.3/howto/sorting.html\n",
    "    s = ['<PAD>','<EOS>'] + train_data['meta']['slot_types']\n",
    "    slot_tag = sorted(set(s), key=lambda x: s.index(x))\n",
    "    i = train_data['meta']['intent_types']\n",
    "    intent_tag = sorted(set(i), key=lambda x: i.index(x))\n",
    "\n",
    "    return vocab, slot_tag, intent_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split_atis(new_atis0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_atis = adjust_sequences(atis_json)#padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "atis_vocab,atis_slots,atis_intents = get_vocabularies(adjusted_atis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(870, 122, 21)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(atis_vocab),len(atis_slots),len(atis_intents)\n",
    "#type(atis_vocab[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next we need to embed the data and set it up for Pytorch\n",
    "Remember each vocabulary for each sentence, slot and intent will have different embeddings. They are different sized vectors. The Network will try to figure out a mapping from these different vector spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mappings(vocab,forward_map):\n",
    "    \"\"\"\n",
    "    This function takes the words in the vocabulary and creates a unique mapping to a number.\n",
    "    :param vocab contains all the words in the corpus.\n",
    "    :param forward_map a dictionary that will be populated with mappings.\n",
    "    returns populated forward_map\n",
    "    \"\"\"\n",
    "    for sample in vocab:\n",
    "        if sample not in forward_map.keys():\n",
    "            forward_map[sample]= len(forward_map)\n",
    "    return forward_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 2\n",
    "EOS_token = 3\n",
    "word2index = {'<PAD>': 0, '<UNK>':1,'<SOS>':2,'<EOS>':3}\n",
    "create_mappings(atis_vocab,word2index)\n",
    "index2word = {v:k for k,v in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2index = {'<PAD>' : 0,'<UNK>':1,'<EOS>':2}\n",
    "create_mappings(atis_slots,tag2index)\n",
    "index2tag = {v:k for k,v in tag2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent2index={'<UNK>':0}\n",
    "create_mappings(atis_intents,intent2index)\n",
    "index2intent = {v:k for k,v in intent2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index['<UNK>']\n",
    "#tag2index['<SOS>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we create a Tensor where each row is a mapped/embedded sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq_data, mapping,map_type):\n",
    "    \"\"\"\n",
    "    :param seq a sequnce which will be embedded as a vector\n",
    "    :param mapping, a dictionary which contains how each element in the seq will be mapped to a number.\n",
    "    :param map_type 'words','slots' or 'intent'\n",
    "    returns a Pytorch Tensor.\n",
    "    \"\"\"\n",
    "    embed_fnc = lambda word: mapping[word] if word in mapping.keys() else mapping[\"<UNK>\"]\n",
    "    embeddings = list(map(embed_fnc, seq_data[map_type]))\n",
    "    tensor = Variable(torch.LongTensor(embeddings)).cuda() if USE_CUDA else Variable(torch.LongTensor(embeddings))\n",
    "    return tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_set(padded_atis):\n",
    "    train_data = []\n",
    "    atis_data = padded_atis['data']\n",
    "    #print(len(atis_data))\n",
    "    for i in range(len(atis_data)):\n",
    "        #print(len(atis_data[i]['words']))\n",
    "        seq_tensor = prepare_sequence(atis_data[i],word2index,'words').view(1,-1)\n",
    "        slot_tensor = prepare_sequence(atis_data[i],tag2index,'slots').view(1,-1)\n",
    "        intent_tensor = prepare_sequence(atis_data[i],intent2index,'intent')#.view(1,-1)\n",
    "        train_data.append((seq_tensor,slot_tensor,intent_tensor))\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = create_training_set(adjusted_atis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4478"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)\n",
    "#train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size, train_data):\n",
    "    \"\"\"\n",
    "    Returns iteratively a batch of specified size on the data. \n",
    "    The last batch can be smaller if the total size is not multiple of the batch\n",
    "    \"\"\"\n",
    "    random.shuffle(train_data)\n",
    "    sindex = 0\n",
    "    eindex = batch_size\n",
    "    while sindex < len(train_data):\n",
    "        batch = train_data[sindex:eindex]\n",
    "        temp = eindex\n",
    "        eindex = eindex + batch_size\n",
    "        sindex = temp\n",
    "        #print('returning', len(batch), 'samples')\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Joint-RNN Model\n",
    "Gives an explanation of encoder-decoder models using RNNs: https://github.com/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb\n",
    "\n",
    "**Note the inputs:**\n",
    "\n",
    "* input_dim is the size/dimensionality of the one-hot vectors that will be input to the encoder. This is equal to the input (source) vocabulary size.\n",
    "* emb_dim is the dimensionality of the embedding layer. This layer converts the one-hot vectors into dense vectors with emb_dim dimensions.\n",
    "* hid_dim is the dimensionality of the hidden and cell states.\n",
    "* n_layers is the number of layers in the RNN.\n",
    "* dropout is the amount of dropout to use. This is a regularization parameter to prevent overfitting. Check out this for more details about dropout.\n",
    "Remember to use progress bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\"BiDir-LSTM\"\"\"\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim,n_layers=1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "       \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers,bidirectional=True)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        # batch size is determined from dimensions of the input.\n",
    "        #src = [sent len, batch size]\n",
    "        embedded = self.embedding(src)\n",
    "\n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "\n",
    "        #outputs = [sent len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "\n",
    "        #outputs are always from the top hidden layer\n",
    "\n",
    "        return hidden , cell # makes up the context vector\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder \n",
    "    \"\"\"\n",
    "    def __init__(self, slot_dim, intent_dim , emb_dim, hid_dim, n_layers=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.slot_dim = slot_dim \n",
    "        self.intent_dim = intent_dim\n",
    "        \n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        \n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(slot_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers)\n",
    "        \n",
    "        self.out = nn.Linear(hid_dim, slot_dim) #slot output\n",
    "        self.intent_out = nn.Linear(hid_dim,intent_dim) # intent output\n",
    "        \n",
    "    def forward(self, input_dec, hidden, cell):\n",
    "        \n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #n directions in the decoder will both always be 1, therefore:\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #context = [n layers, batch size, hid dim]\n",
    "        \n",
    "        #input_enc = [1, batch size]   \n",
    "        #input_dec = input_dec # current word\n",
    "        print(input_dec.shape)\n",
    "        \n",
    "        embedded = self.embedding(input_dec)\n",
    "        #embedded = [1, batch size, emb dim]\n",
    "        #print('embed ',embedded)\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        \n",
    "        #output = [sentence len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #sentence len and n directions will always be 1 in the decoder, therefore:\n",
    "        #output = [1, batch size, hid dim]\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #cell = [n layers, batch size, hid dim]\n",
    "        \n",
    "        slot_prediction = self.out(output.squeeze(0))\n",
    "        intent_prediction = self.intent_out(output.squeeze(0))\n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        return slot_prediction, intent_prediction\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to figure out how data flows through model, dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing models...\n",
      "torch.Size([1, 50])\n",
      "torch.Size([1, 50])\n",
      "encoder_cell torch.Size([2, 50, 5])\n",
      "encoder_hidden torch.Size([2, 50, 5])\n",
      "torch.Size([1, 50])\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing models...\")\n",
    "n_layers = 1\n",
    "INPUT_DIM = len(atis_vocab)\n",
    "OUTPUT_DIM = len(atis_slots)\n",
    "#print(INPUT_DIM,OUTPUT_DIM)\n",
    "intent_size = 1\n",
    "embed_size = 5\n",
    "hidden_size = 5\n",
    "output_size = MAX_LENGTH\n",
    "encoder = Encoder(INPUT_DIM, embed_size,hidden_size,n_layers=n_layers)\n",
    "decoder = Decoder(OUTPUT_DIM,intent_size,embed_size ,hidden_size, n_layers=2)\n",
    "\n",
    "# Test encoder\n",
    "inp = get_batch(1,train_data[:1])\n",
    "for i in inp:\n",
    "    print(i[0][0].shape) # [batch size , sent len] needs to be [sent len, batch size] cause pytorch accepts that\n",
    "    print(i[0][1].shape)\n",
    "    encoder_hidden, encoder_cell = encoder(i[0][0])\n",
    "print('encoder_cell', encoder_cell.size())\n",
    "print('encoder_hidden', encoder_hidden.size())\n",
    "\n",
    "# Test decoder\n",
    "# First feed Decoder <SOS> token\n",
    "decoder_input = i[0][0]#Variable(torch.LongTensor([[0]])) # SOS\n",
    "decoder_hidden = encoder_hidden\n",
    "decoder_cell = encoder_cell\n",
    "dec_slot_output, dec_intent_output = decoder(decoder_input, decoder_hidden, decoder_cell)\n",
    "# print('dec_slot_output dim : ' ,dec_slot_output.size())\n",
    "# print('dec_intent_output dim: ', dec_intent_output.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE=0.001\n",
    "EMBEDDING_SIZE=64\n",
    "HIDDEN_SIZE=64\n",
    "BATCH_SIZE=16\n",
    "LENGTH=50\n",
    "STEP_SIZE=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    \n",
    "\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "        loss += criterion(decoder_output, target_tensor[di])\n",
    "        if decoder_input.item() == EOS_token:\n",
    "            break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
